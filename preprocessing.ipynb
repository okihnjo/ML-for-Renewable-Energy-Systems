{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read multiple csv from data folder\n",
    "files = []\n",
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(file)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "path_to_germany = \"./data/vg2500_geo84/vg2500_bld.shp\"\n",
    "germany_gdf = gpd.read_file(path_to_germany)\n",
    "germany_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot germany with grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/' + files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(df.longitude, df.latitude)]\n",
    "geo_df = gpd.GeoDataFrame(df, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "germany_gdf.plot(ax=ax, color='lightgrey')\n",
    "\n",
    "geo_df.plot(ax=ax, marker='o', color='red', markersize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate the map of germany into a grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate midpoints\n",
    "mid_latitude = df['latitude'].mean()\n",
    "mid_longitude = df['longitude'].mean()\n",
    "\n",
    "def categorize_location(row):\n",
    "    if row['latitude'] >= mid_latitude and row['longitude'] <= mid_longitude:\n",
    "        return 'top_left'\n",
    "    elif row['latitude'] >= mid_latitude and row['longitude'] > mid_longitude:\n",
    "        return 'top_right'\n",
    "    elif row['latitude'] < mid_latitude and row['longitude'] <= mid_longitude:\n",
    "        return 'bottom_left'\n",
    "    else:\n",
    "        return 'bottom_right'\n",
    "\n",
    "# Apply the function to create the new 'location' column\n",
    "df['location'] = df.apply(categorize_location, axis=1)\n",
    "df['location']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each location seperately\n",
    "fig, ax = plt.subplots()\n",
    "for i in df['location'].unique():\n",
    "    temp_df = df[df['location'] == i]\n",
    "    ax.scatter(temp_df['longitude'], temp_df['latitude'], label=i)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataframe with only important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"blh\",\"tcc\", \"tsr\", \"sund\", \"tp\", \"fsr\", \"cdir\", \"z\", \"msl\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply = pd.read_csv('data/' + files[2], sep=';')\n",
    "df_realized_supply.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply = df_realized_supply[['Date from', 'Date to', \"Photovoltaic [MW]\", \"Wind Offshore [MW] \", \"Wind Onshore [MW]\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply[\"wind_on_offshore\"] = df_realized_supply[\"Wind Offshore [MW] \"] + df_realized_supply[\"Wind Onshore [MW]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply = df_realized_supply.drop(columns=[\"Wind Offshore [MW] \", \"Wind Onshore [MW]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply[\"photo\"] = df_realized_supply[\"Photovoltaic [MW]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply = df_realized_supply.drop(columns=[\"Photovoltaic [MW]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "x_axis = df_realized_supply[\"Date from\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_realized_supply.photo,\n",
    "                    )\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "x_axis = df_realized_supply[\"Date from\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_realized_supply.wind_on_offshore,\n",
    "                    )\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get year and month from date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply[\"timestamps\"] = pd.to_datetime(df_realized_supply[\"Date from\"])\n",
    "df_realized_supply['month_year'] = df_realized_supply['timestamps'].dt.strftime('%Y-%m')\n",
    "df_realized_supply['day'] = df_realized_supply['timestamps'].dt.strftime('%d')\n",
    "df_realized_supply[\"fullhour\"] = df_realized_supply['timestamps'].dt.strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_realized_supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take every 4th row\n",
    "df_full_hour = df_realized_supply.iloc[::4, :]\n",
    "df_full_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_4_hours = df_realized_supply.iloc[::16, :]\n",
    "df_full_4_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_6_hours = df_realized_supply.iloc[::24, :]\n",
    "df_full_6_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ssr(value):\n",
    "    # Remove everything after the comma\n",
    "    if type(value) != float:\n",
    "        value = value.split(',')[0]\n",
    "        # Remove any periods that are used as thousand separators\n",
    "        value = value.replace('.', '')\n",
    "        # Convert to float\n",
    "    return float(value)\n",
    "df_realized_supply[\"photo\"] = df_realized_supply[\"photo\"].apply(preprocess_ssr)\n",
    "df_realized_supply[\"wind_on_offshore\"] = df_realized_supply[\"wind_on_offshore\"].apply(preprocess_ssr)\n",
    "\n",
    "df_full_hour[\"photo\"] = df_realized_supply[\"photo\"].apply(preprocess_ssr)\n",
    "df_full_hour[\"wind_on_offshore\"] = df_realized_supply[\"wind_on_offshore\"].apply(preprocess_ssr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_full_4_hours[\"photo\"] = df_realized_supply[\"photo\"].apply(preprocess_ssr)\n",
    "df_full_4_hours[\"wind_on_offshore\"] = df_realized_supply[\"wind_on_offshore\"].apply(preprocess_ssr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_realized_supply.groupby('month_year')[\"photo\"].mean().reset_index()\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"month_year\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per month\",\n",
    "    xaxis_title=\"Month\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take weakly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df_realized_supply.resample('H', on=\"timestamps\").photo.mean().reset_index()\n",
    "\n",
    "df_daily = df_hourly.resample('D', on=\"timestamps\").photo.mean().reset_index()\n",
    "\n",
    "df_weekly = df_daily.resample('W', on='timestamps').photo.mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.sort_values(by=\"timestamps\", inplace=True)\n",
    "df_agg = df_hourly\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"timestamps\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per hour\",\n",
    "    xaxis_title=\"hour\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly.sort_values(by=\"timestamps\", inplace=True)\n",
    "df_agg = df_weekly\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"timestamps\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per hour\",\n",
    "    xaxis_title=\"week\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "df_final = df_weekly\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n",
    "\n",
    "values = df_train['photo']\n",
    "values_test = df_test['photo']\n",
    "\n",
    "# Fit a state space model using SARIMAX\n",
    "model = SARIMAX(values, order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))  # Monthly seasonality\n",
    "fit = model.fit(disp=False)\n",
    "\n",
    "# Get the filtered state estimates\n",
    "filtered_state_means = fit.filter_results.filtered_state[0]\n",
    "\n",
    "# Convert the filtered values to a Pandas series\n",
    "filtered_series = pd.Series(filtered_state_means, df_train[\"timestamps\"])\n",
    "state_transition_matrix = fit.filter_results.transition\n",
    "observation_matrix = fit.filter_results.design\n",
    "process_covariance_matrix = fit.filter_results.state_cov\n",
    "measurement_covariance_matrix = fit.filter_results.obs_cov\n",
    "initial_state_mean = fit.filter_results.initial_state\n",
    "initial_state_covariance = fit.filter_results.initial_state_cov\n",
    "\n",
    "# Display the properties\n",
    "print(\"State Transition Matrix (F):\")\n",
    "print(state_transition_matrix)\n",
    "print(\"\\nObservation Matrix (H):\")\n",
    "print(observation_matrix)\n",
    "print(\"\\nProcess Covariance Matrix (Q):\")\n",
    "print(process_covariance_matrix)\n",
    "print(\"\\nMeasurement Covariance Matrix (R):\")\n",
    "print(measurement_covariance_matrix)\n",
    "print(\"\\nInitial State Mean:\")\n",
    "print(initial_state_mean)\n",
    "print(\"\\nInitial State Covariance:\")\n",
    "print(initial_state_covariance)\n",
    "\n",
    "\n",
    "# Plot the original and filtered time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_train[\"timestamps\"], values, label='Original')\n",
    "plt.plot(filtered_series.index, filtered_series, label='Filtered')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filtered Time Series')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "predictions_test = fit.get_forecast(steps=len(df_test))\n",
    "predicted_mean_test = predictions_test.predicted_mean\n",
    "\n",
    "weekly_pred_df = pd.DataFrame({'predicted_mean': predicted_mean_test})\n",
    "weekly_pred_df.index = df_test[\"timestamps\"]\n",
    "# Resample to daily frequency and interpolate\n",
    "hourly_predictions = weekly_pred_df.resample('H').interpolate()\n",
    "\n",
    "\n",
    "# Plot the original and predicted time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_train[\"timestamps\"], values, label='Train')\n",
    "plt.plot(df_test[\"timestamps\"], values_test, label='Test')\n",
    "plt.plot(hourly_predictions.index, hourly_predictions, label='hourly Predictions')\n",
    "plt.plot(df_test[\"timestamps\"], predicted_mean_test, label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Predicted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hourly_predictions.index, hourly_predictions, label='Daily Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_pred_df = pd.DataFrame({'predicted_mean': predicted_mean_test})\n",
    "weekly_pred_df.index = df_test[\"timestamps\"]\n",
    "# Resample to daily frequency and interpolate\n",
    "daily_predictions = weekly_pred_df.resample('D').interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_predictions.index, daily_predictions, label='Daily Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_certain_time = df_hourly[df_hourly[\"timestamps\"]>=\"2022-01-02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_hourly_certain_time[\"timestamps\"], df_hourly_certain_time[\"photo\"], label='Hourly vals')\n",
    "plt.plot(hourly_predictions.index, hourly_predictions, label='hourly Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_certain_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_index_2 = pd.date_range(start=df_weekly[\"timestamps\"].min(), end=df_weekly[\"timestamps\"].max(), freq='H')\n",
    "hourly_index_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an hourly date range that covers the period of the original hourly data\n",
    "hourly_index = pd.date_range(start=df_weekly.index.min(), end=df_weekly.index.max(), freq='H')\n",
    "\n",
    "\n",
    "# Reindex to ensure hourly_predictions covers the entire hourly_index range\n",
    "hourly_predictions_2 = hourly_predictions.reindex(hourly_index_2).interpolate()\n",
    "hourly_predictions_2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the size to prevent excessive plotting issues\n",
    "hourly_predictions_3 = hourly_predictions_2.loc[hourly_predictions.index.min():hourly_predictions.index.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_hourly is your hourly data DataFrame\n",
    "df_hourly['timestamps'] = pd.to_datetime(df_hourly['timestamps'])\n",
    "df_hourly.set_index('timestamps', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_predictions_3 = hourly_predictions_3[hourly_predictions_3.index.isin(df_hourly.index)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_predictions_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Align hourly_predictions with the original hourly data\n",
    "# hourly_predictions = hourly_predictions.reindex(df_hourly.index).interpolate()\n",
    "\n",
    "# Calculate residuals on the training set\n",
    "residuals_train = df_hourly.loc[hourly_predictions_3.index, 'photo'] - hourly_predictions_3.loc[hourly_predictions_3.index, 'predicted_mean']\n",
    "\n",
    "# Plot residuals\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(residuals_train.index, residuals_train, label='Residuals')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals from SARIMAX Model')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Kalman Filter with better-informed parameters\n",
    "from pykalman import KalmanFilter\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=[1],\n",
    "    observation_matrices=[1],\n",
    "    initial_state_mean=residuals_train.mean(),\n",
    "    initial_state_covariance=np.var(residuals_train),\n",
    "    observation_covariance=np.var(residuals_train),\n",
    "    transition_covariance=np.eye(1) * 0.01\n",
    ")\n",
    "\n",
    "# Fit the Kalman Filter on the residuals\n",
    "kf_state_means, kf_state_covariances = kf.smooth(residuals_train.values)\n",
    "\n",
    "# Convert the filtered values to a Pandas series\n",
    "kalman_filtered_residuals = pd.Series(kf_state_means.flatten(), index=residuals_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_state_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the hourly predictions with the Kalman filter output\n",
    "combined_predictions = hourly_predictions_3['predicted_mean'] + kalman_filtered_residuals.reindex(hourly_predictions_3.index, method='nearest')\n",
    "\n",
    "# Limit the size to prevent excessive plotting issues\n",
    "# combined_predictions = combined_predictions.loc[df_hourly.index.min():df_hourly.index.max()]\n",
    "\n",
    "# Plot the original, hourly, and combined predictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_hourly.index, df_hourly['photo'], label='Original')\n",
    "plt.plot(hourly_predictions_3.index, hourly_predictions_3, label='Hourly Predictions')\n",
    "plt.plot(combined_predictions.index, combined_predictions, label='Combined Predictions')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Hourly vs Combined Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_hour.sort_values(by=\"timestamps\", inplace=True)\n",
    "df_agg = df_full_hour\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"timestamps\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per hour\",\n",
    "    xaxis_title=\"week\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_weekly[df_weekly[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_weekly[df_weekly[\"timestamps\"] >= \"2022-01-01\"]\n",
    "\n",
    "values_train = df_train['photo']\n",
    "values_test = df_test['photo']\n",
    "values_train.fillna(0, inplace=True)\n",
    "kf = KalmanFilter(\n",
    "    n_dim_obs=1,  # Dimension of observations (1 because we have a single PV output variable)\n",
    "    n_dim_state=2,  # Dimension of state variables (level and trend)\n",
    "    em_vars=['transition_matrices', 'observation_matrices', 'transition_covariance', 'observation_covariance', 'initial_state_mean', 'initial_state_covariance']\n",
    ")\n",
    "\n",
    "# Use the EM algorithm to estimate parameters from the training data\n",
    "kf = kf.em(values_train, n_iter=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"timstamp\"] = pd.to_datetime(df_train[\"timestamps\"])\n",
    "df_train.set_index(\"timstamp\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Kalman filter to smooth the data\n",
    "(smoothed_state_means_train, smoothed_state_covariances_train) = kf.smooth(values_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_state_means_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the smoothed state means to a Pandas series\n",
    "smoothed_series = pd.Series(smoothed_state_means_train[:, 0], index=df_train.index)  # Use the first state variable (level)\n",
    "\n",
    "# Plot the original and smoothed time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_train.index, values_train, label='Original')\n",
    "plt.plot(df_train.index, smoothed_series, label='Smoothed')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Smoothed Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the next steps using the last state from the training data\n",
    "n_test_steps = len(values_test)\n",
    "predicted_means = []\n",
    "\n",
    "# Initialize state with the last smoothed state from training\n",
    "current_state_mean = smoothed_state_means_train[-1]\n",
    "current_state_covariance = smoothed_state_covariances_train[-1]\n",
    "\n",
    "for t in range(n_test_steps):\n",
    "    # Predict the next step\n",
    "    current_state_mean, current_state_covariance = kf.filter_update(\n",
    "        current_state_mean, current_state_covariance, observation=None, transition_matrix=kf.transition_matrices, observation_matrix=kf.observation_matrices, transition_covariance=kf.transition_covariance,\n",
    "    )\n",
    "    predicted_means.append(current_state_mean[0])\n",
    "\n",
    "predicted_means = np.array(predicted_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Transition matrix:\\n\", kf.transition_matrices)\n",
    "print(\"Observation matrix:\\n\", kf.observation_matrices)\n",
    "print(\"Transition covariance:\\n\", kf.transition_covariance)\n",
    "print(\"Observation covariance:\\n\", kf.observation_covariance)\n",
    "print(\"Initial state mean:\\n\", kf.initial_state_mean)\n",
    "print(\"Initial state covariance:\\n\", kf.initial_state_covariance)\n",
    "\n",
    "\n",
    "# Print the initial state used for predictions\n",
    "print(\"Initial state mean for predictions:\\n\", initial_state_mean)\n",
    "print(\"Initial state covariance for predictions:\\n\", initial_state_covariance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if array has na\n",
    "values_test.fillna(0, inplace=True)\n",
    "np.isnan(predicted_means).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Evaluate the predictions\n",
    "r2 = r2_score(values_test, predicted_means)\n",
    "mse = mean_squared_error(values_test, predicted_means)\n",
    "\n",
    "\n",
    "print(f'R^2: {r2:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "\n",
    "# Convert the predicted values to a Pandas series for plotting\n",
    "predicted_series = pd.Series(predicted_means, index=df_test[\"timestamps\"])\n",
    "\n",
    "# Plot the original and predicted time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "# plt.plot(df_train.index, df_train['photo'], label='Train')\n",
    "# plt.plot(df_test.index, df_test['photo'], label='Test')\n",
    "plt.plot(predicted_series.index, predicted_series, label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Predicted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Step 1: Generate Synthetic Data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate a date range for one year of hourly data\n",
    "date_range = pd.date_range(start='2020-01-01', end='2020-12-31 23:00:00', freq='H')\n",
    "\n",
    "# Generate synthetic data: a combination of a sinusoidal pattern and random noise\n",
    "sin_pattern = np.sin(np.linspace(0, 2 * np.pi * 4, len(date_range))) * 100  # Sinusoidal pattern (4 cycles per year)\n",
    "trend = np.linspace(50, 150, len(date_range))  # Linear trend\n",
    "noise = np.random.normal(0, 10, len(date_range))  # Random noise\n",
    "synthetic_data = sin_pattern + trend + noise\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'timestamps': date_range, 'photo': synthetic_data})\n",
    "df.set_index('timestamps', inplace=True)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "split_date = '2020-10-01'\n",
    "df_train = df[df.index < split_date]\n",
    "df_test = df[df.index >= split_date]\n",
    "\n",
    "values_train = df_train['photo'].values\n",
    "values_test = df_test['photo'].values\n",
    "\n",
    "# Step 2: Initialize and Train the Kalman Filter with EM Algorithm\n",
    "kf = KalmanFilter(\n",
    "    n_dim_obs=1,  # Dimension of observations (1 because we have a single PV output variable)\n",
    "    n_dim_state=2,  # Dimension of state variables (level and trend)\n",
    "    em_vars=['transition_matrices', 'observation_matrices', 'transition_covariance', 'observation_covariance', 'initial_state_mean', 'initial_state_covariance']\n",
    ")\n",
    "\n",
    "kf = kf.em(values_train, n_iter=20)\n",
    "\n",
    "# Step 3: Smooth the Training Data\n",
    "(smoothed_state_means_train, smoothed_state_covariances_train) = kf.smooth(values_train)\n",
    "\n",
    "# Plot the original and smoothed time series\n",
    "smoothed_series = pd.Series(smoothed_state_means_train[:, 0], index=df_train.index)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_train.index, values_train, label='Original')\n",
    "plt.plot(smoothed_series.index, smoothed_series, label='Smoothed')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Smoothed Time Series')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Predict the Test Data\n",
    "def predict_kalman_filter(kf, initial_state_mean, initial_state_covariance, n_steps):\n",
    "    predicted_means = []\n",
    "    current_state_mean = initial_state_mean\n",
    "    current_state_covariance = initial_state_covariance\n",
    "    \n",
    "    for t in range(n_steps):\n",
    "        current_state_mean, current_state_covariance = kf.filter_update(\n",
    "            current_state_mean, current_state_covariance, observation=None\n",
    "        )\n",
    "        predicted_means.append(current_state_mean[0])\n",
    "    \n",
    "    return np.array(predicted_means)\n",
    "\n",
    "initial_state_mean = smoothed_state_means_train[-1]\n",
    "initial_state_covariance = smoothed_state_covariances_train[-1]\n",
    "n_test_steps = len(values_test)\n",
    "\n",
    "predicted_means = predict_kalman_filter(kf, initial_state_mean, initial_state_covariance, n_test_steps)\n",
    "\n",
    "# Step 5: Evaluate and Plot the Results\n",
    "r2 = r2_score(values_test, predicted_means)\n",
    "mse = mean_squared_error(values_test, predicted_means)\n",
    "\n",
    "print(f'R^2: {r2:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "\n",
    "predicted_series = pd.Series(predicted_means, index=df_test.index)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df_train.index, df_train['photo'], label='Train')\n",
    "plt.plot(df_test.index, df_test['photo'], label='Test')\n",
    "plt.plot(predicted_series.index, predicted_series, label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original vs Predicted Time Series')\n",
    "plt.show()\n",
    "\n",
    "# Debugging: Print Kalman Filter Parameters\n",
    "print(\"Transition matrix:\\n\", kf.transition_matrices)\n",
    "print(\"Observation matrix:\\n\", kf.observation_matrices)\n",
    "print(\"Transition covariance:\\n\", kf.transition_covariance)\n",
    "print(\"Observation covariance:\\n\", kf.observation_covariance)\n",
    "print(\"Initial state mean:\\n\", kf.initial_state_mean)\n",
    "print(\"Initial state covariance:\\n\", kf.initial_state_covariance)\n",
    "print(\"Initial state mean for predictions:\\n\", initial_state_mean)\n",
    "print(\"Initial state covariance for predictions:\\n\", initial_state_covariance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Generate synthetic time series data\n",
    "np.random.seed(0)\n",
    "time = np.linspace(0, 10, 500)\n",
    "values = 100 + 10 * np.sin(time) + np.random.normal(size=time.shape) * 2\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'date': pd.date_range(start='2020-01-01', periods=len(time), freq='D'), 'value': values})\n",
    "\n",
    "# Prepare the time series\n",
    "values = data['value'].values\n",
    "\n",
    "# Initial state mean\n",
    "initial_state_mean = values[0]\n",
    "\n",
    "# Observation matrix\n",
    "observation_matrix = np.array([[1]])\n",
    "\n",
    "# Transition matrix\n",
    "transition_matrix = np.array([[1]])\n",
    "\n",
    "# Process and observation noise covariance matrices\n",
    "observation_covariance = np.diag([0.1])  # Tuning required\n",
    "transition_covariance = np.diag([0.1])  # Tuning required\n",
    "\n",
    "# Create the Kalman Filter instance\n",
    "kf = KalmanFilter(\n",
    "   n_dim_obs=1,  # Dimension of observations (1 because we have a single PV output variable)\n",
    "    n_dim_state=2,  # Dimension of state variables (level and trend)\n",
    "    em_vars=['transition_matrices', 'observation_matrices', 'transition_covariance', 'observation_covariance', 'initial_state_mean', 'initial_state_covariance']\n",
    ")\n",
    "\n",
    "# Fit the filter\n",
    "kf = kf.em(values, n_iter=10)  # EM algorithm to estimate the parameters\n",
    "\n",
    "# Apply the filter to the data\n",
    "filtered_state_means, filtered_state_covariances = kf.filter(values)\n",
    "n_forecast = 50\n",
    "last_filtered_state_mean = filtered_state_means[-1]\n",
    "forecasted_state_means = last_filtered_state_mean\n",
    "forecasted_values = [last_filtered_state_mean]\n",
    "\n",
    "for _ in range(n_forecast):\n",
    "    forecasted_state_means = np.dot(transition_matrix, forecasted_state_means)\n",
    "    forecasted_values.append(forecasted_state_means[0])  # Ensure consistent shape\n",
    "\n",
    "forecasted_values = np.array(forecasted_values)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['date'], values, label='Original')\n",
    "plt.plot(data['date'], filtered_state_means, label='Filtered')\n",
    "plt.plot(pd.date_range(start=data['date'].iloc[-1], periods=n_forecast + 1, freq='D')[1:], forecasted_values, label='Forecasted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filter - Original, Filtered and Forecasted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Generate synthetic time series data\n",
    "np.random.seed(0)\n",
    "time = np.linspace(0, 10, 500)\n",
    "values = 100 + 10 * np.sin(time) + np.random.normal(size=time.shape) * 2\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'date': pd.date_range(start='2020-01-01', periods=len(time), freq='D'), 'value': values})\n",
    "\n",
    "# Prepare the time series\n",
    "values = data['value'].values\n",
    "\n",
    "# Create the Kalman Filter instance\n",
    "kf = KalmanFilter(\n",
    "    n_dim_obs=1,  # Dimension of observations (1 because we have a single PV output variable)\n",
    "    n_dim_state=2,  # Dimension of state variables (level and trend)\n",
    "    em_vars=['transition_matrices', 'observation_matrices', 'transition_covariance', 'observation_covariance', 'initial_state_mean', 'initial_state_covariance']\n",
    ")\n",
    "\n",
    "# Initial guess of the state mean and covariance\n",
    "initial_state_mean = [values[0], 0]\n",
    "initial_state_covariance = np.eye(2)\n",
    "\n",
    "# Fit the filter using the EM algorithm\n",
    "kf = kf.em(values, n_iter=10)  # EM algorithm to estimate the parameters\n",
    "\n",
    "# Apply the filter to the data\n",
    "filtered_state_means, filtered_state_covariances = kf.filter(values.reshape(-1, 1))\n",
    "\n",
    "# Forecast future values\n",
    "n_forecast = 50\n",
    "last_filtered_state_mean = filtered_state_means[-1]\n",
    "forecasted_state_means = last_filtered_state_mean\n",
    "forecasted_values = []\n",
    "print(kf.transition_matrices)\n",
    "\n",
    "for _ in range(n_forecast):\n",
    "    forecasted_state_means = kf.transition_matrices @ forecasted_state_means\n",
    "    forecasted_values.append(forecasted_state_means[0])\n",
    "\n",
    "forecasted_values = np.array(forecasted_values)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "# plt.plot(data['date'], values, label='Original')\n",
    "# plt.plot(data['date'], filtered_state_means[:, 0], label='Filtered')\n",
    "plt.plot(pd.date_range(start=data['date'].iloc[-1], periods=n_forecast + 1, freq='D')[1:], forecasted_values, label='Forecasted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filter - Original, Filtered and Forecasted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Generate synthetic time series data\n",
    "np.random.seed(0)\n",
    "time = np.linspace(0, 10, 500)\n",
    "values = 100 + 10 * np.sin(time) + np.random.normal(size=time.shape) * 2\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'date': pd.date_range(start='2020-01-01', periods=len(time), freq='D'), 'value': values})\n",
    "\n",
    "# Prepare the time series\n",
    "values = data['value'].values\n",
    "\n",
    "# Define the Kalman Filter parameters\n",
    "period = 2 * np.pi  # Example period of the sinusoid\n",
    "omega = 2 * np.pi / period  # Angular frequency\n",
    "\n",
    "# Transition matrix for capturing sinusoidal patterns\n",
    "transition_matrix = np.array([\n",
    "    [1, 1, 0, 0],\n",
    "    [0, 1, -omega, 0],\n",
    "    [0, 0, np.cos(omega), -np.sin(omega)],\n",
    "    [0, 0, np.sin(omega), np.cos(omega)]\n",
    "])\n",
    "\n",
    "# Observation matrix\n",
    "observation_matrix = np.array([[1, 0, 1, 0]])\n",
    "\n",
    "# Initial state and covariance\n",
    "initial_state_mean = [values[0], 0, 0, 0]  # Initial state [position, velocity, sin_component, cos_component]\n",
    "initial_state_covariance = np.eye(4)  # Initial state covariance\n",
    "\n",
    "# Observation and transition covariance\n",
    "observation_covariance = np.eye(1) * 0.1  # Observation noise\n",
    "transition_covariance = np.eye(4) * 0.1  # Process noise\n",
    "\n",
    "# Create the Kalman Filter instance\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=transition_matrix,\n",
    "    observation_matrices=observation_matrix,\n",
    "    initial_state_mean=initial_state_mean,\n",
    "    initial_state_covariance=initial_state_covariance,\n",
    "    observation_covariance=observation_covariance,\n",
    "    transition_covariance=transition_covariance\n",
    ")\n",
    "\n",
    "# Fit the filter using the EM algorithm\n",
    "kf = kf.em(values.reshape(-1, 1), n_iter=140)  # EM algorithm to estimate the parameters\n",
    "\n",
    "# Apply the filter to the data\n",
    "filtered_state_means, filtered_state_covariances = kf.filter(values.reshape(-1, 1))\n",
    "\n",
    "# Forecast future values\n",
    "n_forecast = 50\n",
    "last_filtered_state_mean = filtered_state_means[-1]\n",
    "forecasted_state_means = last_filtered_state_mean\n",
    "forecasted_values = []\n",
    "\n",
    "for _ in range(n_forecast):\n",
    "    forecasted_state_means = np.dot(kf.transition_matrices, forecasted_state_means)\n",
    "    forecasted_values.append(forecasted_state_means[0])\n",
    "\n",
    "forecasted_values = np.array(forecasted_values)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['date'], values, label='Original')\n",
    "plt.plot(data['date'], filtered_state_means[:, 0], label='Filtered')\n",
    "plt.plot(pd.date_range(start=data['date'].iloc[-1], periods=n_forecast + 1, freq='D')[1:], forecasted_values, label='Forecasted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filter - Original, Filtered and Forecasted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Generate synthetic time series data\n",
    "np.random.seed(0)\n",
    "time = np.linspace(0, 10, 500)\n",
    "values = 100 + 10 * np.sin(time) + np.random.normal(size=time.shape) * 2\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'date': pd.date_range(start='2020-01-01', periods=len(time), freq='D'), 'value': values})\n",
    "\n",
    "# Prepare the time series\n",
    "values = data['value'].values\n",
    "\n",
    "# Define the Kalman Filter parameters\n",
    "# More complex transition matrix to capture sinusoidal patterns\n",
    "dt = 1  # Time step\n",
    "omega = 2 * np.pi / len(time)  # Angular frequency\n",
    "\n",
    "transition_matrix = np.array([\n",
    "    [1, dt, 0.5 * dt**2],\n",
    "    [0, 1, dt],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "observation_matrix = np.array([[1, 0, 0]])  # We observe the position only\n",
    "\n",
    "# Initial state and covariance\n",
    "initial_state_mean = [values[0], 0, 0]  # Initial position, velocity, and acceleration\n",
    "initial_state_covariance = np.eye(3)  # Initial state covariance\n",
    "\n",
    "# Observation and transition covariance\n",
    "observation_covariance = np.eye(1) * 0.1  # Observation noise\n",
    "transition_covariance = np.eye(3) * 0.1  # Process noise\n",
    "\n",
    "# Create the Kalman Filter instance\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=transition_matrix,\n",
    "    observation_matrices=observation_matrix,\n",
    "    initial_state_mean=initial_state_mean,\n",
    "    initial_state_covariance=initial_state_covariance,\n",
    "    observation_covariance=observation_covariance,\n",
    "    transition_covariance=transition_covariance\n",
    ")\n",
    "\n",
    "# Fit the filter using the EM algorithm\n",
    "kf = kf.em(values.reshape(-1, 1), n_iter=10)  # EM algorithm to estimate the parameters\n",
    "\n",
    "# Apply the filter to the data\n",
    "filtered_state_means, filtered_state_covariances = kf.filter(values.reshape(-1, 1))\n",
    "\n",
    "# Forecast future values using filter_update\n",
    "n_forecast = 50\n",
    "last_state_mean = filtered_state_means[-1]\n",
    "last_state_covariance = filtered_state_covariances[-1]\n",
    "forecasted_values = []\n",
    "\n",
    "for _ in range(n_forecast):\n",
    "    last_state_mean, last_state_covariance = kf.filter_update(\n",
    "        last_state_mean, last_state_covariance\n",
    "    )\n",
    "    forecasted_values.append(last_state_mean[0])\n",
    "\n",
    "forecasted_values = np.array(forecasted_values)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data['date'], values, label='Original')\n",
    "plt.plot(data['date'], filtered_state_means[:, 0], label='Filtered')\n",
    "plt.plot(pd.date_range(start=data['date'].iloc[-1], periods=n_forecast + 1, freq='D')[1:], forecasted_values, label='Forecasted')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filter - Original, Filtered and Forecasted Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly[df_hourly[\"photo\"].isnull()][\"photo\"] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.metrics import mape\n",
    "from darts.metrics.metrics import rmse, mae, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_hourly\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n",
    "\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_test = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=80)\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(len(series_test))\n",
    "# Validation\n",
    "pred_val = forecast\n",
    "val_error = mape(forecast, series_test)\n",
    "print(f'MAPE on validation set: {val_error:.2f}%')\n",
    "\n",
    "eval = rmse(series_test, forecast)\n",
    "eval_mae = mae(series_test, forecast)\n",
    "r2 = r2_score(series_test, forecast)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_test.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "dates = pd.date_range(start='2019-01-01', periods=365 * 2, freq='D')  # 2 years of daily data\n",
    "seasonal_pattern = 10 + 2 * np.sin(np.linspace(0, 3.14 * 2 * 4, len(dates)))  # Seasonal pattern\n",
    "noise = np.random.normal(0, 1, len(dates))  # Noise\n",
    "\n",
    "values = seasonal_pattern + noise\n",
    "data = pd.DataFrame({'date': dates, 'value': values})\n",
    "data.to_csv('sample_data.csv', index=False)\n",
    "\n",
    "# Display the generated data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Generate example data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "dates = pd.date_range(start='2019-01-01', periods=365 * 2, freq='D')  # 2 years of daily data\n",
    "seasonal_pattern = 10 + 2 * np.sin(np.linspace(0, 3.14 * 2 * 4, len(dates)))  # Seasonal pattern\n",
    "noise = np.random.normal(0, 1, len(dates))  # Noise\n",
    "\n",
    "values = seasonal_pattern + noise\n",
    "data = pd.DataFrame({'date': dates, 'value': values})\n",
    "data.to_csv('sample_data.csv', index=False)\n",
    "\n",
    "# Load the generated sample data\n",
    "data = pd.read_csv('sample_data.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Extract the time series values\n",
    "values = data['value']\n",
    "\n",
    "# Fit a state space model using SARIMAX\n",
    "model = SARIMAX(values, order=(1, 1, 1), seasonal_order=(1, 1, 1, 30))  # Monthly seasonality\n",
    "fit = model.fit(disp=False)\n",
    "\n",
    "# Get the filtered state estimates\n",
    "filtered_state_means = fit.filter_results.filtered_state[0]\n",
    "\n",
    "# Convert the filtered values to a Pandas series\n",
    "filtered_series = pd.Series(filtered_state_means, index=data.index)\n",
    "\n",
    "# Plot the original and filtered time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(data.index, values, label='Original')\n",
    "plt.plot(filtered_series.index, filtered_series, label='Filtered')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filtered Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "df_final = df_hourly\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n",
    "\n",
    "values = df_train['photo']\n",
    "\n",
    "# Fit a state space model using SARIMAX\n",
    "model = SARIMAX(values, order=(1, 1, 1), seasonal_order=(1, 1, 1, 30))  # Monthly seasonality\n",
    "fit = model.fit(disp=True, maxiter=10)\n",
    "\n",
    "# Get the filtered state estimates\n",
    "filtered_state_means = fit.filter_results.filtered_state[0]\n",
    "\n",
    "# Convert the filtered values to a Pandas series\n",
    "filtered_series = pd.Series(filtered_state_means, index=data.index)\n",
    "\n",
    "# Plot the original and filtered time series\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(data.index, values, label='Original')\n",
    "plt.plot(filtered_series.index, filtered_series, label='Filtered')\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Kalman Filtered Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_daily\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"timestamps\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per day (actual)\",\n",
    "    xaxis_title=\"week\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly.sort_values(by=\"timestamps\", inplace=True)\n",
    "df_agg = df_weekly\n",
    "fig = go.Figure()\n",
    "x_axis = df_agg[\"timestamps\"]\n",
    "\n",
    "fig  = px.line(x=x_axis, y=df_agg.photo,\n",
    "                    )\n",
    "# title\n",
    "fig.update_layout(\n",
    "    title=\"Average photovoltaic power supply per week (actual)\",\n",
    "    xaxis_title=\"week\",\n",
    "    yaxis_title=\"Power supply [MW]\",\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ssr with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamps\"] = pd.to_datetime(df[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly_ssr = df.resample('H', on=\"timestamps\")[\"ssr\"].mean().reset_index()\n",
    "df_daily_ssr = df_hourly_ssr.resample('D', on=\"timestamps\")[\"ssr\"].mean().reset_index()\n",
    "df_weekly_ssr =df_daily_ssr.resample('W', on=\"timestamps\")[\"ssr\"].mean().reset_index()\n",
    "df_weekly_ssr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_joined = pd.merge(df_daily, df_daily_ssr, on=\"timestamps\", how=\"inner\")\n",
    "df_joined = df_daily\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.datasets import AirPassengersDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.metrics.metrics import rmse, mae, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2021-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2021-01-01\"]\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_actual = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=100\n",
    "                         )\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(365)\n",
    "\n",
    "eval = rmse(series_actual, forecast)\n",
    "eval_mae = mae(series_actual, forecast)\n",
    "r2 = r2_score(series_actual, forecast)\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_actual.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2021-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2021-01-01\"]\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_actual = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=200\n",
    "                         )\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(365)\n",
    "\n",
    "eval = rmse(series_actual, forecast)\n",
    "eval_mae = mae(series_actual, forecast)\n",
    "r2 = r2_score(series_actual, forecast)\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_actual.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2021-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2021-01-01\"]\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_actual = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=146\n",
    "                         \n",
    "                         )\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(365)\n",
    "\n",
    "eval = rmse(series_actual, forecast)\n",
    "eval_mae = mae(series_actual, forecast)\n",
    "r2 = r2_score(series_actual, forecast)\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_actual.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2021-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2021-01-01\"]\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_actual = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=220\n",
    "                         \n",
    "                         )\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(730)\n",
    "\n",
    "eval = rmse(series_actual, forecast)\n",
    "eval_mae = mae(series_actual, forecast)\n",
    "r2 = r2_score(series_actual, forecast)\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_actual.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find good amount of hiddenstates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start training..\")\n",
    "time_start = time.time()\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_actual = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "best_eval = 0\n",
    "best_mae = 0\n",
    "best_r2 = 0\n",
    "best_number_states = 1\n",
    "best_series = series\n",
    "\n",
    "second_best_eval = 0\n",
    "second_best_mae = 0\n",
    "second_best_r2 = 0\n",
    "second_best_number_states = 1\n",
    "\n",
    "for i in range(220,285):\n",
    "\n",
    "    model = KalmanForecaster(dim_x=i)\n",
    "    model.fit(series)\n",
    "\n",
    "    forecast = model.predict(365)\n",
    "\n",
    "    eval = rmse(series_actual, forecast)\n",
    "    eval_mae = mae(series_actual, forecast)\n",
    "    r2 = r2_score(series_actual, forecast)\n",
    "    if i%10==0:\n",
    "        print(f\"Step: {i}\")\n",
    "    if r2 > best_r2:\n",
    "\n",
    "\n",
    "        second_best_eval = best_eval\n",
    "        second_best_mae = best_mae\n",
    "        second_best_r2 = best_r2\n",
    "        second_best_number_states = best_number_states\n",
    "        \n",
    "        best_eval = eval\n",
    "        best_mae = eval_mae\n",
    "        best_r2 = r2\n",
    "        best_number_states = i\n",
    "\n",
    "        best_series = forecast\n",
    "print(\"training finished\")\n",
    "print(f\"duration:  {time.time()- time_start}\")\n",
    "\n",
    "print(f\"RMSE: {best_eval}, MAE: {best_mae}, R2: {best_r2}, best_number_states: {best_number_states} \\n\")\n",
    "print(f\"Second: RMSE: {second_best_eval}, MAE: {second_best_mae}, R2: {second_best_r2}, best_number_states: {second_best_number_states}\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_actual.plot(label='test_vals')\n",
    "best_series.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = KalmanForecaster(dim_x=120)  # Specify the number of components (states)\n",
    "model.fit(series)\n",
    "\n",
    "# Forecast the next 20 time steps\n",
    "forecast = model.predict(60)\n",
    "\n",
    "# Plot the original series and the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='Actual')\n",
    "forecast.plot(label='Forecast')\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.datasets import AirPassengersDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_joined, 'timestamps', ['photo', \"ssr\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=34)  # Specify the number of components (states)\n",
    "model.fit(series)\n",
    "\n",
    "# Forecast the next 20 time steps\n",
    "forecast = model.predict(60)\n",
    "\n",
    "# Plot the original series and the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='Actual')\n",
    "forecast.plot(label='Forecast')\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.datasets import AirPassengersDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_joined[['photo', 'ssr']] = scaler.fit_transform(df_joined[['photo', 'ssr']])\n",
    "series = TimeSeries.from_dataframe(df_joined, 'timestamps', ['photo', \"ssr\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=34)  # Specify the number of components (states)\n",
    "model.fit(series)\n",
    "\n",
    "# Forecast the next 20 time steps\n",
    "forecast = model.predict(60)\n",
    "\n",
    "# Plot the original series and the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='Actual')\n",
    "forecast.plot(label='Forecast')\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(df_joined[['photo', 'ssr']])\n",
    "df_joined[['photo', 'ssr']] = scaled_values\n",
    "\n",
    "# Create a TimeSeries object with both 'photo' and 'ssr' columns\n",
    "series = TimeSeries.from_dataframe(df_joined, 'timestamps', ['photo', 'ssr'])\n",
    "\n",
    "# Initialize the KalmanForecaster with the appropriate dimension\n",
    "model = KalmanForecaster(dim_x=34)  # Adjust dim_x based on the complexity needed\n",
    "model.fit(series)\n",
    "\n",
    "# Forecast the next 60 time steps\n",
    "forecast = model.predict(60)\n",
    "\n",
    "# Inverse transform the forecast data to the original scale\n",
    "forecast_df = pd.DataFrame(forecast.pd_dataframe(), columns=['photo', 'ssr'])\n",
    "forecast_inverse = scaler.inverse_transform(forecast_df)\n",
    "\n",
    "# Reconstruct the TimeSeries object from the inverse transformed data\n",
    "forecast_series = TimeSeries.from_dataframe(\n",
    "    pd.DataFrame(forecast_inverse, index=forecast.time_index, columns=['photo', 'ssr']),\n",
    "    time_col=None\n",
    ")\n",
    "\n",
    "# Plot the original series and the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='Actual')\n",
    "forecast_series.plot(label='Forecast')\n",
    "plt.legend()\n",
    "plt.title('lol')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_values = scaler.fit_transform(df_joined[['photo']])\n",
    "df_joined[['photo']] = scaled_values\n",
    "\n",
    "# Create a TimeSeries object with both 'photo' and 'ssr' columns\n",
    "series = TimeSeries.from_dataframe(df_joined, 'timestamps', ['photo'])\n",
    "\n",
    "# Initialize the KalmanForecaster with the appropriate dimension\n",
    "model = KalmanForecaster(dim_x=34)  # Adjust dim_x based on the complexity needed\n",
    "model.fit(series)\n",
    "\n",
    "# Forecast the next 60 time steps\n",
    "forecast = model.predict(60)\n",
    "\n",
    "# Inverse transform the forecast data to the original scale\n",
    "forecast_df = pd.DataFrame(forecast.pd_dataframe(), columns=['photo'])\n",
    "forecast_inverse = scaler.inverse_transform(forecast_df)\n",
    "\n",
    "# Reconstruct the TimeSeries object from the inverse transformed data\n",
    "forecast_series = TimeSeries.from_dataframe(\n",
    "    pd.DataFrame(forecast_inverse, index=forecast.time_index, columns=['photo']),\n",
    "    time_col=None\n",
    ")\n",
    "\n",
    "# Plot the original series and the forecast\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='Actual')\n",
    "forecast.plot(label='Forecast')\n",
    "plt.legend()\n",
    "plt.title('Forecast with only photovoltaic power supply')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Was wurde in der Masterarbeit gemacht ?\n",
    "- Exponential Smoothing um Model zu erstellen\n",
    "- Trend, seasonality und residual\n",
    "- Dabei wurde in jedem Update step von Kalman auch die Parameter des Models geändert\n",
    "- Parameter wurden mit Maximum Likelihood geschätzt\n",
    "- Das Model als State Transition Model\n",
    "- Die Messungen als Observation Model\n",
    "- Das hat nur gut geklappt, weil das rausfinden des zugrundeliegenden Models durch die seasonalität und pattern möglich war\n",
    "- hat auch autocorrelation genutzt um das window für die Tage zu finden - clever\n",
    "\n",
    "## Problem für mich\n",
    "- Exponential smoothing aufwändig\n",
    "- Updaten von 2 Modellen so gesehen\n",
    "- Auch rechenaufwändig (wie in der Masterarbeit beschrieben)\n",
    "- Masterarbeitaufwand vs Seminararbeit 3 ects\n",
    "- Bedarf kompletter Eigenimplementierung ohne Bibliothek\n",
    "\n",
    "## Lösung\n",
    "- Kalman verstanden\n",
    "- Problemstellung verstanden\n",
    "- Warum die Kombi nicht so gut ist in diesem Fall\n",
    "- wann sie gut wäre (und was man machen müsste damit es hier gut ist)\n",
    "- Nutze dennoch darts und erkläre N4SID\n",
    "- Damit hätten wir:\n",
    "    - State Space models\n",
    "    - Kalman Filter\n",
    "    - Usecases wo und wann er gut ist, was die einzelnen Komponenten sind\n",
    "    - Vorgehen\n",
    "    - Bezug auf unser Projekt, inwiefern das hier anwendbar ist\n",
    "    - Lösung: N4SID und Kalman mittels Darts Implementierung\n",
    "    - Fazit\n",
    "\n",
    "\n",
    "## Fragen\n",
    "- Macht es riesen Unterschied ob SSR und Photo oder nur Photo ?\n",
    "- Multivariate vs Univariat ?\n",
    "- Darts Implementierung etwas schwammig, hidden states nicht einsehbar, genauso wie die Kovarianzen - schlimm ?\n",
    "Immerhin beschreibe ich ja was die jeweils machen und wie sie zusammenhängen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.models import KalmanForecaster\n",
    "from darts.metrics import mape\n",
    "\n",
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2021-06-01\"]\n",
    "df_val = df_final[(df_final[\"timestamps\"]>=\"2021-06-01\") & (df_final[\"timestamps\"]<\"2022-01-01\")] \n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_val = TimeSeries.from_dataframe(df_val, \"timestamps\", [\"photo\"])\n",
    "\n",
    "\n",
    "series_test = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=280)\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(len(series_val))\n",
    "# Validation\n",
    "pred_val = forecast\n",
    "val_error = mape(series_val, pred_val)\n",
    "print(f'MAPE on validation set: {val_error:.2f}%')\n",
    "\n",
    "eval = rmse(series_val, forecast)\n",
    "eval_mae = mae(series_val, forecast)\n",
    "r2 = r2_score(series_val, forecast)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "\n",
    "print(\"training again..\")\n",
    "combined_train_val = series.append(series_val)\n",
    "model.fit(combined_train_val)\n",
    "# Final testing\n",
    "pred_test = model.predict(len(series_test))\n",
    "test_error = mape(series_test, pred_test)\n",
    "print(f'MAPE on test set: {test_error:.2f}%')\n",
    "eval = rmse(pred_test, series_test)\n",
    "eval_mae = mae(pred_test, series_test)\n",
    "r2 = r2_score(pred_test, series_test)\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "combined_train_val.plot(label='train')\n",
    "series_test.plot(label='test_vals')\n",
    "pred_test.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_joined\n",
    "df_train = df_final[df_final[\"timestamps\"] < \"2022-01-01\"]\n",
    "df_test = df_final[df_final[\"timestamps\"]>=\"2022-01-01\"]\n",
    "\n",
    "\n",
    "series = TimeSeries.from_dataframe(df_train, \"timestamps\", [\"photo\"])\n",
    "series_test = TimeSeries.from_dataframe(df_test, \"timestamps\", [\"photo\"])\n",
    "\n",
    "model = KalmanForecaster(dim_x=280)\n",
    "model.fit(series)\n",
    "\n",
    "forecast = model.predict(len(series_test))\n",
    "# Validation\n",
    "pred_val = forecast\n",
    "val_error = mape(forecast, series_test)\n",
    "print(f'MAPE on validation set: {val_error:.2f}%')\n",
    "\n",
    "eval = rmse(series_test, forecast)\n",
    "eval_mae = mae(series_test, forecast)\n",
    "r2 = r2_score(series_test, forecast)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(eval)\n",
    "print(eval_mae)\n",
    "print(r2)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "series.plot(label='train')\n",
    "series_test.plot(label='test_vals')\n",
    "forecast.plot(label='Forecast')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Kalman Filter Forecast using N4SID')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_timesteps = 100\n",
    "solar_radiation = np.random.rand(n_timesteps)  # Simulated solar radiation data\n",
    "pv_output = 2 * solar_radiation + np.random.randn(n_timesteps) * 0.1  # Simulated photovoltaic output data\n",
    "\n",
    "# Normalize the data\n",
    "solar_radiation = (solar_radiation - np.mean(solar_radiation)) / np.std(solar_radiation)\n",
    "pv_output = (pv_output - np.mean(pv_output)) / np.std(pv_output)\n",
    "\n",
    "# Dimensions\n",
    "n_dim_state = 1  # We assume the state is one-dimensional (PV output)\n",
    "n_dim_obs = 1  # We assume the observation is one-dimensional (solar radiation)\n",
    "\n",
    "# Random initialization\n",
    "transition_matrix = np.eye(n_dim_state)  # F: Identity matrix for state transition\n",
    "observation_matrix = np.random.randn(n_dim_obs, n_dim_state)  # H: Random initialization\n",
    "initial_state_mean = np.random.randn(n_dim_state)  # Initial state\n",
    "initial_state_covariance = np.eye(n_dim_state)  # Initial state covariance\n",
    "transition_covariance = np.eye(n_dim_state)  # Q: Process noise covariance\n",
    "observation_covariance = np.eye(n_dim_obs)  # R: Measurement noise covariance\n",
    "transition_offsets = np.zeros(n_dim_state)  # Transition offsets\n",
    "observation_offset = np.zeros(n_dim_obs)  # Observation offsets\n",
    "\n",
    "# Initialize Kalman Filter with random parameters\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=transition_matrix,\n",
    "    observation_matrices=observation_matrix,\n",
    "    transition_covariance=transition_covariance,\n",
    "    observation_covariance=observation_covariance,\n",
    "    transition_offsets=transition_offsets,\n",
    "    observation_offsets=observation_offset,\n",
    "    initial_state_mean=initial_state_mean,\n",
    "    initial_state_covariance=initial_state_covariance,\n",
    "    em_vars=[\n",
    "        'transition_matrices', 'observation_matrices',\n",
    "        'transition_covariance', 'observation_covariance',\n",
    "        'observation_offsets', 'initial_state_mean',\n",
    "        'initial_state_covariance'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Observations are the solar radiation data\n",
    "observations = solar_radiation.reshape(-1, 1)\n",
    "\n",
    "# Estimate parameters using EM algorithm\n",
    "loglikelihoods = np.zeros(10)\n",
    "for i in range(len(loglikelihoods)):\n",
    "    kf = kf.em(X=observations, n_iter=1)\n",
    "    loglikelihoods[i] = kf.loglikelihood(observations)\n",
    "\n",
    "# Filtering\n",
    "filtered_state_estimates = kf.filter(observations)[0]\n",
    "\n",
    "# Plot results\n",
    "pl.figure(figsize=(16, 6))\n",
    "lines_obs = pl.plot(observations, linestyle='-', color='b', label='Solar Radiation (observations)')\n",
    "lines_filt = pl.plot(filtered_state_estimates, linestyle='--', color='g', label='Filtered PV Output (state estimate)')\n",
    "pl.legend()\n",
    "pl.xlabel('Time')\n",
    "pl.ylabel('Normalized Value')\n",
    "pl.show()\n",
    "\n",
    "# Plot log likelihoods\n",
    "pl.figure()\n",
    "pl.plot(loglikelihoods)\n",
    "pl.xlabel('EM iteration number')\n",
    "pl.ylabel('Log likelihood')\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_timesteps = 100\n",
    "solar_radiation = np.random.rand(n_timesteps)  # Simulated solar radiation data\n",
    "pv_output = 2 * solar_radiation + np.random.randn(n_timesteps) * 0.1  # Simulated photovoltaic output data\n",
    "\n",
    "# Normalize the data\n",
    "solar_radiation = (solar_radiation - np.mean(solar_radiation)) / np.std(solar_radiation)\n",
    "pv_output = (pv_output - np.mean(pv_output)) / np.std(pv_output)\n",
    "\n",
    "# Prepare matrices\n",
    "x = pv_output.reshape(-1, 1)  # Hidden states (PV output)\n",
    "z = solar_radiation.reshape(-1, 1)  # Observations (solar radiation)\n",
    "\n",
    "M = n_timesteps\n",
    "\n",
    "# Estimate A, W, H, Q using the closed-form solutions\n",
    "A = np.dot(x[1:].T, x[:-1]) @ np.linalg.inv(np.dot(x[:-1].T, x[:-1]))\n",
    "W = (np.dot(x[1:].T, x[1:]) - np.dot(A, np.dot(x[:-1].T, x[1:]))) / (M - 1)\n",
    "H = np.dot(z.T, x) @ np.linalg.inv(np.dot(x.T, x))\n",
    "Q = (np.dot(z.T, z) - np.dot(H, np.dot(x.T, z))) / M\n",
    "\n",
    "# Convert to correct shapes\n",
    "A = A.reshape(1, 1)\n",
    "W = W.reshape(1, 1)\n",
    "H = H.reshape(1, 1)\n",
    "Q = Q.reshape(1, 1)\n",
    "\n",
    "# Initialize Kalman Filter with estimated parameters\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=A,\n",
    "    observation_matrices=H,\n",
    "    transition_covariance=W,\n",
    "    observation_covariance=Q,\n",
    "    initial_state_mean=x[0],\n",
    "    initial_state_covariance=np.eye(1)\n",
    ")\n",
    "\n",
    "# Filter the observations to estimate the states\n",
    "filtered_state_estimates = kf.filter(z)[0]\n",
    "\n",
    "# Plot results\n",
    "pl.figure(figsize=(16, 6))\n",
    "lines_true = pl.plot(x, linestyle='-', color='b', label='True PV Output (hidden state)')\n",
    "lines_obs = pl.plot(z, linestyle=':', color='m', label='Solar Radiation (observation)')\n",
    "lines_filt = pl.plot(filtered_state_estimates, linestyle='--', color='g', label='Filtered PV Output (state estimate)')\n",
    "pl.legend()\n",
    "pl.xlabel('Time')\n",
    "pl.ylabel('Normalized Value')\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_timesteps = 100\n",
    "solar_radiation = np.random.rand(n_timesteps)  # Simulated solar radiation data\n",
    "pv_output = 2 * solar_radiation + np.random.randn(n_timesteps) * 0.1  # Simulated photovoltaic output data\n",
    "\n",
    "# Normalize the data\n",
    "solar_radiation = (solar_radiation - np.mean(solar_radiation)) / np.std(solar_radiation)\n",
    "pv_output = (pv_output - np.mean(pv_output)) / np.std(pv_output)\n",
    "\n",
    "# Prepare matrices\n",
    "x = pv_output.reshape(-1, 1)  # Hidden states (PV output)\n",
    "z = solar_radiation.reshape(-1, 1)  # Observations (solar radiation)\n",
    "\n",
    "M = n_timesteps\n",
    "\n",
    "# Estimate A, W, H, Q using the closed-form solutions\n",
    "A = np.dot(x[1:].T, x[:-1]) @ np.linalg.inv(np.dot(x[:-1].T, x[:-1]))\n",
    "W = (np.dot(x[1:].T, x[1:]) - np.dot(A, np.dot(x[:-1].T, x[1:]))) / (M - 1)\n",
    "H = np.dot(z.T, x) @ np.linalg.inv(np.dot(x.T, x))\n",
    "Q = (np.dot(z.T, z) - np.dot(H, np.dot(x.T, z))) / M\n",
    "\n",
    "# Convert to correct shapes\n",
    "A = A.reshape(1, 1)\n",
    "W = W.reshape(1, 1)\n",
    "H = H.reshape(1, 1)\n",
    "Q = Q.reshape(1, 1)\n",
    "\n",
    "# Initialize Kalman Filter with estimated parameters\n",
    "kf = KalmanFilter(\n",
    "    transition_matrices=A,\n",
    "    observation_matrices=H,\n",
    "    transition_covariance=W,\n",
    "    observation_covariance=Q,\n",
    "    initial_state_mean=x[0],\n",
    "    initial_state_covariance=np.eye(1)\n",
    ")\n",
    "\n",
    "# Filter the observations to estimate the states\n",
    "filtered_state_estimates = kf.filter(z)[0]\n",
    "\n",
    "# Plot results\n",
    "pl.figure(figsize=(16, 6))\n",
    "lines_true = pl.plot(x, linestyle='-', color='b', label='True PV Output (hidden state)')\n",
    "lines_obs = pl.plot(z, linestyle=':', color='m', label='Solar Radiation (observation)')\n",
    "lines_filt = pl.plot(filtered_state_estimates, linestyle='--', color='g', label='Filtered PV Output (state estimate)')\n",
    "pl.legend()\n",
    "pl.xlabel('Time')\n",
    "pl.ylabel('Normalized Value')\n",
    "pl.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
